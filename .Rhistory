# introducing the interaction term between bill length and species - *
m3 <-
glm(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm * species) %>%
summary()
m1$aic
m2$aic
m2$aic
library(easystats)
install.packages("easystats")
library(easystats)
compare_performance(m1,m2,m3)
library(tidyverse)
library(palmerpenguins)
library(easystats)
penguins %>%
ggplot(aes(y=bill_depth_mm,x=bill_length_mm)) +
geom_point() +
geom_smooth(method='lm')
head(penguins)
# make linear regression of this plot
m1 <-
glm(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm)
# according to this model, the average bill depth is 20.88547
# -0.08502 is the slope (m)
# we always visualize first and then we model
# analysis of variance
aov(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm) %>%
summary()
# tells you degrees of freedom, sum of squares, mean fo squares
# this is an anova table. Pr(>F) is the p-value, this only tells you
# if your data is significant, if you chose a good variable comparison.
penguins %>%
ggplot(aes(y=bill_depth_mm,x=bill_length_mm,color=species)) +
geom_point() +
geom_smooth(method='lm')
# this is showing simpson's paradox. Now that they're separated, the
# opposite trend shows now.
# just adding, this takes into account the different species.
m2 <-
glm(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm + species)
# the table is more confusing now. The intercept is 10.6
# this picks the default categorical variables based on the alphabet,
# adele became the intercept species. The other estimates tell you what
# to subtract from the default
# here, slope is the same for all the species
# introducing the interaction term between bill length and species - *
m3 <-
glm(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm * species)
# here the slope can change based on the species
# "tell me the effect of species AND the slope"
# aic is telling you which is capturing reality the best.
m1$aic
m2$aic
m2$aic
compare_performance(m1,m2,m3)
# from easystats
compare_performance(m1,m2,m3) %>% plot
names(penguins)
m4 <-
glm(data=penguins,
formula=bill_depth_mm ~ bill_length_mm * species + sex)
# from easystats
compare_performance(m1,m2,m3,m4) %>% plot
penguins %>%
ggplot(aes(y=bill_depth_mm,x=bill_length_mm,color=species)) +
geom_point() +
geom_smooth(method='lm',linetype=sex)
penguins %>%
ggplot(aes(y=bill_depth_mm,x=bill_length_mm,color=species)) +
geom_point() +
geom_smooth(method='lm',aes(linetype=sex))
m4 <-
glm(data=penguins,
formula=bill_depth_mm ~ bill_length_mm * species + sex + island)
# from easystats
compare_performance(m1,m2,m3,m4) %>% plot
penguins %>%
ggplot(aes(y=bill_depth_mm,x=bill_length_mm,color=species)) +
geom_point() +
geom_smooth(method='lm',aes(linetype=sex)) +
facet_wrap(~island)
formula(m4)
x <-
data.frame(bill_length_mm = 5000,
species = "Chinstrap",
sex = "male",
island = "Dream")
# we're gonna go with model 4, lets do some predicting
predict(m4,x) # it needs all the variables exactly to do a prediction
x <-
data.frame(bill_length_mm = c(5000,100),
species = c("Chinstrap","Chinstrap"),
sex = c("male","male"),
island = c("Dream","Dream"))
# we're gonna go with model 4, lets do some predicting
predict(m4,x) # it needs all the variables exactly to do a prediction
mpg %>%
ggplot(aes(x=displ,y=hwy,color=factor(cyl))) +
geom_plot() +
geom_smooth(method='lm')
mpg %>%
ggplot(aes(x=displ,y=hwy,color=factor(cyl))) +
geom_point() +
geom_smooth(method='lm')
m5 <- glm(data=mpg, formula=hwy~displ)
predict(m5,y)
# here the model lied to us, if you know more about cars, you can see the
# error in model. The bigger the v8 engine, you do not get better gas mileage
y <- data.fram(displ=500)
# here the model lied to us, if you know more about cars, you can see the
# error in model. The bigger the v8 engine, you do not get better gas mileage
y <- data.frame(displ=500)
m5 <- glm(data=mpg, formula=hwy~displ)
predict(m5,y)
# it is important to not predict outside of the data you've seen.
a <- data.frame(displ=4.5)
m9 <- glm(data=mpg, formula=hwy~displ)
predict(m9,a)
predict(m5,a)
m6 <- glm(data=mpg, formula=hwy~log(displ))
ggplot(aes(x=log(displ),y=hwy) +
geom_smooth(method='lm')
geom_smooth(method='lm',formula = y ~ log(displ))
geom_smooth(method='lm',fomrula = y ~ log(x))
geom_smooth(method='lm',formula = y ~ log(x))
geom_smooth(method='lm',formula = y ~ log(x))
mpg %>%
ggplot(aes(x=(displ),y=hwy)) +
geom_point() +
geom_smooth(method='lm',formula = y ~ log(x))
# new built in
Titanic
# new built in
Titanic %>%  as.data.frame()
# so far we've been predicting continuous variable, what about categorical
df <- read_csv("./Data/GradSchool_Admissions.csv")
View(df)
glm(data=df,
formula=admit~gre+gpa+rank)
m6 <- glm(data=df,
formula=admit~gre+gpa+rank)
m6 <- glm(data=df,
formula=admit~gre+gpa+rank) %>%
summary()
m6
df <-
df %>%
mutate(admit = as.logical(admit))
m6 <- glm(data=df,
formula=admit~gre+gpa+rank) %>%
m6 <- glm(data=df,
formula=admit~gre+gpa+rank) %>%
summary()
m6
# logistic -> family = 'binomial'
m6 <- glm(data = df,
formula = admit~gre+gpa+rank,
family = "binomial") %>%
summary()
m6
library(modelr)
add_predictions(df,m6)
library(modelr)
# logistic -> family = 'binomial'
m6 <- glm(data = df,
formula = admit~gre+gpa+rank,
family = "binomial")
add_predictions(df,m6)
add_predictions(df,m6,type="response")
add_predictions(df,m6,type="response") %>%
ggplot(aes(x=gpa,y=pred)) +
geom_smooth()
add_predictions(df,m6,type="response") %>%
# don't forget type, it's what gives us percentages !!!!!
ggplot(aes(x=gpa,y=pred)) +
geom_smooth()
add_predictions(df,m6,type="response") %>%
# don't forget type, it's what gives us percentages !!!!!
ggplot(aes(x=gpa,y=pred,color=rank)) +
geom_smooth()
# don't forget type, it's what gives us percentages !!!!!
ggplot(aes(x=gpa,y=pred,color=factor(rank)) +
geom_smooth()
add_predictions(df,m6,type="response") %>%
add_predictions(df,m6,type="response") %>%
# don't forget type, it's what gives us percentages !!!!!
ggplot(aes(x=gpa,y=pred,color=factor(rank))) +
geom_smooth()
library(tidyverse)
library(janitor)
library(readxl)
path <- "./Data/Messy_bp.xlsx"
# the data starts lower so we're not going to see column names
# data starts on A4 and ends on M24
# range lets you fix what is shown
df <- read_xlsx(path, range = "A4:M24") %>% clean_names()
# interaction is shown with the *
m7 <- glm(data = df,
formula = admit~gre*gpa*rank,
family = "binomial")
summary(m7)
library(tidyverse)
library(palmerpenguins)
library(easystats)
# interaction is shown with the *
m7 <- glm(data = df,
formula = admit~gre*gpa*rank,
family = "binomial")
summary(m7)
# so far we've been predicting continuous variable, what about categorical
#### logistic regression -> outcome is T/F ####
df <- read_csv("./Data/GradSchool_Admissions.csv")
df <-
df %>%
mutate(admit = as.logical(admit))
# interaction is shown with the *
m7 <- glm(data = df,
formula = admit~gre*gpa*rank,
family = "binomial")
summary(m7)
# interaction is shown with the *
m7 <- glm(data = df,
formula = admit~gre*gpa*rank,
family = "binomial")
compare_performance(m6,m7)
# logistic -> family = 'binomial'
m6 <- glm(data = df,
formula = admit~gre+gpa+rank,
family = "binomial") # the predictors are gre, gpa, and rank (separate)
compare_performance(m6,m7)
compare_performance(m6,m7) %>% plot
# magic trick to get the mathematically best model - might not fit reality
# come up with the best most complicated model.
library(MASS)
stepAIC(m7)
step <- stepAIC(m7)
# AIC will find the simplelist best model
step$formula
mod_best <- glm(data=df, family="binomial", formula = step$formula)
compare_performance(m6,m7,mod_best) %>% plot
View(df)
p <- penguins
View(p)
glm(data=p,formula=bill_length_mm ~ species*island*bill_depth_mm*flipper_length_mm*body_mass_g*sex*year)
m8 <- glm(data=p,formula=bill_length_mm ~ species*island*bill_depth_mm*flipper_length_mm*body_mass_g*sex*year)
stepAIC(m8)
step1 <- stepAIC(m8)
step1$formula
# magic shortcut
m8 <- glm(data=p,formula=bill_length_mm ~ .^2)
step1 <- stepAIC(m8)
step1$formula
best_mod1 <-  glm(data=penguins,formula=step1$formula)
library(tidyverse)
library(palmerpenguins)
library(easystats)
penguins %>%
ggplot(aes(y=bill_depth_mm,x=bill_length_mm)) +
geom_point() +
geom_smooth(method='lm')
head(penguins)
# make linear regression of this plot
m1 <-
glm(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm)
# according to this model, the average bill depth is 20.88547
# -0.08502 is the slope (m)
# we always visualize first and then we model
# analysis of variance
aov(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm) %>%
summary()
# tells you degrees of freedom, sum of squares, mean fo squares
# this is an anova table. Pr(>F) is the p-value, this only tells you
# if your data is significant, if you chose a good variable comparison.
penguins %>%
ggplot(aes(y=bill_depth_mm,x=bill_length_mm,color=species)) +
geom_point() +
geom_smooth(method='lm',aes(linetype=sex)) +
facet_wrap(~island)
# this is showing simpson's paradox. Now that they're separated, the
# opposite trend shows now.
# just adding, this takes into account the different species.
m2 <-
glm(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm + species)
# the table is more confusing now. The intercept is 10.6
# this picks the default categorical variables based on the alphabet,
# adele became the intercept species. The other estimates tell you what
# to subtract from the default
# here, slope is the same for all the species
# introducing the interaction term between bill length and species - *
m3 <-
glm(data = penguins,
formula =  bill_depth_mm ~ bill_length_mm * species)
# here the slope can change based on the species
# "tell me the effect of species AND the slope"
# aic is telling you which is capturing reality the best.
m1$aic
m2$aic
m2$aic
m4 <-
glm(data=penguins,
formula=bill_depth_mm ~ bill_length_mm * species + sex + island)
# what would a plot of this look like?
# same as before but facet_wrap on sex. or geom_smooth could have a
# aes(linetype=sex)
# from easystats
compare_performance(m1,m2,m3,m4) %>% plot
# R2 tells you how much variance there are to the lines. Tells you the percent
# improvement with your models
# piping to plot shows you the area to compare which is better, larger area
# does better. These show that model 2 is our best model. Our goal with a
# model is simplicity ( and generalized). It won't be perfect, but it needs
# to be helpful.
formula(m4)
x <-
data.frame(bill_length_mm = c(5000,100),
species = c("Chinstrap","Chinstrap"),
sex = c("male","male"),
island = c("Dream","Dream"))
# we're gonna go with model 4, lets do some predicting
predict(m4,x) # it needs all the variables exactly to do a prediction
mpg %>%
ggplot(aes(x=(displ),y=hwy)) +
geom_point() +
geom_smooth(method='lm',formula = y ~ log(x))
# here the model lied to us, if you know more about cars, you can see the
# error in model. The bigger the v8 engine, you do not get better gas mileage
y <- data.frame(displ=500)
m5 <- glm(data=mpg, formula=hwy~displ)
predict(m5,y) # thermodynamics says this is not possible
# it is important to not predict outside of the data you've seen.
a <- data.frame(displ=4.5)
predict(m5,a)
# transform the data
m6 <- glm(data=mpg, formula=hwy~log(displ))
predict(m5,a)
# new built in
Titanic %>%  as.data.frame()
# so far we've been predicting continuous variable, what about categorical
#### logistic regression -> outcome is T/F ####
df <- read_csv("./Data/GradSchool_Admissions.csv")
df <-
df %>%
mutate(admit = as.logical(admit))
# logistic -> family = 'binomial'
m6 <- glm(data = df,
formula = admit~gre+gpa+rank,
family = "binomial") # the predictors are gre, gpa, and rank (separate)
m6 # these are log odds, we want percentages
# interaction is shown with the *
m7 <- glm(data = df,
formula = admit~gre*gpa*rank,
family = "binomial")
compare_performance(m6,m7) %>% plot # comparing the models
# magic trick to get the mathematically best model - might not fit reality
# come up with the best most complicated model.
library(MASS)
m7 <- glm(data = df,
formula = admit~gre*gpa*rank,
family = "binomial")
step <- stepAIC(m7)
# AIC will find the simplelist best model
step$formula # this spits out the best simplified model
mod_best <- glm(data=df, family="binomial", formula = step$formula)
compare_performance(m6,m7,mod_best) %>% plot
# magic shortcut
full_mod <- glm(data=p,formula=bill_length_mm ~ .^2)
compare_performance(full_mod,best_mod1) %>% plot
.2*344
penguins
caret::
rbinom(10,1,.5)
rbinom(nrow(penguins),1,.8)
penguins <-
penguins %>%
mutate(newcol=rbinom(nrow(penguins),1,.8))
View(penguins)
train <- penguins %>% filter(newcol == 1)
test <- penguins %>% filter(newcol == 0)
.2*344 # let's train on 80%, test on 20%
mod_best <- glm(data=train,formula=step1$formula)
# test model on test set
predictions <-
add_predictions(test,mod_best)
# test model on test set
predictions <-
add_predictions(test,mod_best)
library(modelr)
# test model on test set
predictions <-
add_predictions(test,mod_best)
View(predictions)
predictions %>%
mutate(resid = abs(pred - bill_length_mm)) # what is leftover
mean(predictions$resid)
mean(predictions$resid,na.rm=TRUE)
# calculate the absolute difference between actual and predicted bill length
predictions %>%
mutate(resid = abs(pred - bill_length_mm)) # what is leftover
# calculate the absolute difference between actual and predicted bill length
predictions <-
predictions %>%
mutate(resid = abs(pred - bill_length_mm)) # what is leftover
mean(predictions$resid,na.rm=TRUE)
mean_error <- mean(predictions$resid,na.rm=TRUE)
errors <- c()
for(i in 1:100){
penguins <-
penguins %>%
mutate(newcol=rbinom(nrow(penguins),1,.8))
# set 1s to train and 0s to test
train <- penguins %>% filter(newcol == 1)
test <- penguins %>% filter(newcol == 0)
# train model on train
mod_best <- glm(data=train,formula=step1$formula)
# test model on test set
predictions <-
add_predictions(test,mod_best)
# calculate the absolute difference between actual and predicted bill length
predictions <-
predictions %>%
mutate(resid = abs(pred - bill_length_mm)) # what is leftover
mean_error <- mean(predictions$resid,na.rm=TRUE)
errors[1] <- mean_error
}
errors()
errors
errors <- c()
for(i in 1:100){
penguins <-
penguins %>%
mutate(newcol=rbinom(nrow(penguins),1,.8))
# set 1s to train and 0s to test
train <- penguins %>% filter(newcol == 1)
test <- penguins %>% filter(newcol == 0)
# train model on train
mod_best <- glm(data=train,formula=step1$formula)
# test model on test set
predictions <-
add_predictions(test,mod_best)
# calculate the absolute difference between actual and predicted bill length
predictions <-
predictions %>%
mutate(resid = abs(pred - bill_length_mm)) # what is leftover
mean_error <- mean(predictions$resid,na.rm=TRUE)
errors[i] <- mean_error
}
errors
data.frame(errors) %>%
ggplot(aes(x=errors)) +
geom_density()
install.packages("ranger")
library(ranger)
?ranger()
ranger(Species ~ ., data = iris) # prediction species on everything else
r_mod <- ranger(Species ~ ., data = iris) # prediction species on everything else
# classification is referring to Species names
# based on the data I give, what species do I have?
# downfall - there is no formula out at the end, we don't know what tree was used
# all this can do is make predictions, it won't tell you HOW it made the predictions
pred <- predict(r_mod,iris)
pred$predictions
data.frame(iris$Species,pred$predictions)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
read_csv("./Data/Soil_Predators.csv")
read_csv("../Data/Soil_Predators.csv")
path <- read_csv("../Data/Soil_Predators.csv")
path <- "../Data/Soil_Predators.csv"
df <- read_csv(path)
x <- readLines(path,n=2)
x
badcolnames <- readLines(path,n=1)
badcolnames %>% str_replace_all(",_","_") %>% str_split(",")
badcolnames %>% str_replace_all(",_","_") %>% str_split(",") %>% unlist()
df <- read_csv(path,skip=1,col_names=FALSE)
View(df)
badcolnames <- badcolnames %>% str_replace_all(",_","_") %>% str_split(",") %>% unlist()
df <- df %>% select(-c(X25,X26))
df <- df %>% select(-c(X25,X26))
names(df) <- badcolnames
skimr::skim(df)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
df$Predator_species %>% unique
df$prey_richness <-
df %>% select(starts_with("Consumption")) %>% rowSums(na.rm=TRUE)
df %>%
ggplot(aes(x=Predator_development_stage,y=prey_richness,color=Predator_sex))+
geom_boxplot()
df %>%
ggplot(aes(x=Predator_development_stage,y=prey_richness,color=Predator_sex))+
geom_boxplot() %>%
theme_bw()
df %>%
ggplot(aes(x=Predator_development_stage,y=prey_richness,color=Predator_sex))+
geom_boxplot() +
theme_bw()
p <- df %>%
ggplot(aes(x=Predator_development_stage,y=prey_richness,color=Predator_sex))+
geom_boxplot() +
theme_bw()
plotly::ggplotly(p)
install.packages("plotly")
plotly::ggplotly(p)
plotly::ggplotly(p)
